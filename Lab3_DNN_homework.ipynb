{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset \n",
    " \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import struct \n",
    "import pandas as pd \n",
    " \n",
    "# === Step 1: Load MNIST Dataset === \n",
    "def load_mnist_images(filename): \n",
    "    with open(filename, 'rb') as f: \n",
    "        _, num, rows, cols = struct.unpack(\">IIII\", f.read(16)) \n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows * cols) \n",
    "        return images / 255.0 \n",
    " \n",
    "def load_mnist_labels(filename): \n",
    "    with open(filename, 'rb') as f: \n",
    "        _, num = struct.unpack(\">II\", f.read(8)) \n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8) \n",
    "        return labels \n",
    " # Students can experiment to modify number of Train \n",
    "X_train = load_mnist_images(\"train-images.idx3-ubyte___\")[:500]\n",
    "y_train = load_mnist_labels(\"train-labels.idx1-ubyte___\")[:500] \n",
    "X_test = load_mnist_images(\"t10k-images.idx3-ubyte___\")[:200] \n",
    "y_test = load_mnist_labels(\"t10k-labels.idx1-ubyte___\")[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: Activation Functions (Refer to Eq. 6.14 - 6.18) === \n",
    "def relu(x): \n",
    "    return np.maximum(0, x)\n",
    "def tanh(x): \n",
    "    return np.tanh(x) \n",
    "def softplus(x): \n",
    "    return np.log(1 + np.exp(x))\n",
    "def leaky_relu(x, alpha=0.1): \n",
    "    return np.maximum(alpha * x, x)\n",
    " \n",
    "def one_hot(y, num_classes=10): # Refer to Equation 6.36 \n",
    "    return np.eye(num_classes)[y]\n",
    "def cross_entropy(y_pred, y_true): # Refer to Equation 6.36 \n",
    "    return -np.sum(y_true * np.log(y_pred), axis=1)\n",
    "def softmax(a): # Refer to Equation 6.37 \n",
    "    exp_a = np.exp(a - np.max(a, axis=1, keepdims=True))\n",
    "    return exp_a / np.sum(exp_a, axis=1, keepdims=True)\n",
    " \n",
    "def forward_pass(X, weights, activations): # Forward Pass (Eq. 6.19) === \n",
    "    a = X \n",
    "    for W, activation in zip(weights, activations): \n",
    "        a = np.dot(a, W) \n",
    "        if activation == 'relu': \n",
    "            a = relu(a) \n",
    "        elif activation == 'tanh': \n",
    "            a = tanh(a) \n",
    "        elif activation == 'softplus': \n",
    "            a = softplus(a) \n",
    "        elif activation == 'leaky_relu': \n",
    "            a = leaky_relu(a) \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "input_size = 784 \n",
    "hidden1 = 64 \n",
    "hidden2 = 32 \n",
    "output_size = 10 \n",
    "epochs = 30 \n",
    "best_loss = float('inf') \n",
    "best_weights = None\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    # TODO: Randomly initialize weights for each layer \n",
    "    W1 = np.random.randn(input_size, hidden1)\n",
    "    W2 = np.random.randn(hidden1, hidden2)\n",
    "    W3 = np.random.randn(hidden2, output_size)\n",
    " \n",
    "    weights = [W1, W2, W3] \n",
    "    activations = [relu, relu, softmax]  # Students can experiment to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report === Print TP, FP, FN, TN, precision, recall, f1 for each class and overall accuracy\n"
     ]
    }
   ],
   "source": [
    "# === Step 4: Evaluation Metrics (Confusion Matrix, ROC, etc) === \n",
    "def compute_confusion_matrix(y_true, y_pred, num_classes=10): \n",
    "    cm = np.zeros((num_classes, num_classes)) \n",
    "    for i in range(len(y_true)): \n",
    "        cm[y_true[i], y_pred[i]] += 1 \n",
    "    return cm\n",
    "\n",
    "# === ROC Curve === \n",
    "def compute_roc(y_true, y_scores):\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "    thresholds = np.unique(y_scores)\n",
    "    for threshold in thresholds:\n",
    "        y_pred = [1 if i > threshold else 0 for i in y_scores]\n",
    "        cm = compute_confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    return fpr, tpr\n",
    " \n",
    "# === Classification Report === Print TP, FP, FN, TN, precision, recall, f1, accuracy \n",
    "def compute_metrics(cm):\n",
    "    tp = np.diag(cm)\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    tn = np.sum(cm) - (tp + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    return tp, fp, fn, tn, precision, recall, f1, accuracy\n",
    " \n",
    "print(\"=== Classification Report === Print TP, FP, FN, TN, precision, recall, f1 for each class and overall accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  [0. 7. 1. 2. 0. 0. 0. 6. 0. 9.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_15368\\2127079151.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = tp / (tp + fp)\n",
      "C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_15368\\2127079151.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = forward_pass(X_test, weights, activations)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "cm = compute_confusion_matrix(y_test, y_pred)\n",
    "tp, fp, fn, tn, precision, recall, f1, accuracy = compute_metrics(cm)\n",
    "print(\"TP: \", tp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
